---
title: "Getting started with plmm"
output: rmarkdown::html_vignette
author: "Tabitha Peter"
vignette: >
  %\VignetteIndexEntry{Getting started with plmm}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(plmmr)
```

## Introduction 

`plmmr` (which stands for **P**enalized **L**inear **M**ixed **M**odels for **R**) is an `R` package created for the purpose of fitting penalized regression models to high dimensional data, particularly in which the observations are correlated. This kind of data arises often in the context of genetics (*e.g.* GWAS dealing with population structure/family structure), and this will be the motivation for the examples presented here.

At this time, the package is designed for linear regression only -- that is, we are considering only continuous (numeric) outcomes. In many applications with high dimensional data, the objective of statistical models is to identify signals - for example, many GWAS are interested in identifying a set of variants that show evidence of association with an outcome. Practitioners in these situations are often more interested identifying biological pathways than in estimating odds ratios for individual variants. For these applications, treating binary or categorical outcomes as numeric values is a possibility. In the future, we would like to extend this package to handle logistic regression (to handle dichotomous outcomes). 

Since we are focused on penalized regression in this package, `plmmr` offers 3 choices of penalty: the minimax concave (MCP), the smoothly clipped absolute deviation (SCAD), and the least absolute shrinkage and selection operator (LASSO). ^[For data running filebacked, only the LASSO is currently implemented (we are working to expand this)] Much of the work in this package is built on the concepts/techniques provided in the `ncvreg` [package](https://github.com/pbreheny/ncvreg) by [Patrick Breheny](https://myweb.uiowa.edu/pbreheny/). The filebacked computation relies on the `bigsnpr` [package](https://privefl.github.io/bigsnpr/) by [Florian Priv√©](https://privefl.github.io/) and the `biglasso` [package](https://github.com/pbreheny/biglasso) by [Yaohui Zeng](https://scholar.google.com/citations?user=jpEmf04AAAAJ&hl=en) & colleagues. 

`plmmr` currently includes two example data sets: 

  * `admix` is a small data set (197 observations, 100 SNPs) that describes individuals of different ancestry groups. The outcome of `admix` is simulated to include population structure effects (*i.e.* race/ethnicity have an impact on the SNP associations). This data set is available as `.rda` object under the `data/` folder. 
  
  * `penncath_lite` (data on coronary artery disease from the [PennCath study](https://pubmed.ncbi.nlm.nih.gov/21239051/)) is a mid-sized, high dimensional data set (1401 observations, 4217 SNPs) with several health outcomes as well as age and sex information. This data set is a subset of a much larger data set (the original data has over 800K SNPs). For for information on this data set, refer to the [original publication](https://pubmed.ncbi.nlm.nih.gov/21239051/).
  
In this overview, I will provide a demo of the main functions in `plmmr` using the `admix` data. Checkout the 'Working with PLINK files' vignette to see a demo of processing the `penncath_lite` data from the original PLINK file formats. 


## Basic model fitting 

The `admix` data is already formatted to have elements $X$ and $y$, so I can jump right in with a call to `plmmr::plmm()` (our main function):

```{r admix_fit}
admix_fit <- plmm(X = admix$X, y = admix$y)
summary(admix_fit, lambda = admix_fit$lambda[50])
```

The returned `beta_vals` item is a matrix whose rows are $\hat\beta$ coefficients and whose columns represent values of the penalization parameter $\lambda$. By default, `plmm` fits 100 values of $\lambda$ (see the `setup_lambda` function for details). 

```{r}
admix_fit$beta_vals[1:10, 97:100] |> 
  knitr::kable(digits = 3,
               format = "html")
```

Note that for all values of $\lambda$, SNP 8 has $\hat \beta = 0$. This is because SNP 8 is a constant feature, a feature (column) whose values do not vary among the members of this population.

We can summarize our fit at the nth $\lambda$ value:  

```{r summary1}
# for n = 25 
summary(admix_fit, lambda = admix_fit$lambda[25])
```

We can also plot the path of the fit to see how model coefficients vary with $\lambda$:

```{r admix_plots, fig.align='center', fig.width=8, fig.cap="Plot of path for model fit"}
plot(admix_fit)
```

Suppose we also know the ancestry groups with which for each person in the `admix` data self-identified. We would probably want to include this in the model as an unpenalized covariate (i.e., we would want 'ancestry' to always be in the model). Here is how that could look: 

```{r}
X_plus_ancestry <- cbind(admix$race, admix$X)
colnames(X_plus_ancestry) <- c("ancestry", colnames(admix$X))
admix_fit2 <- plmm(X = X_plus_ancestry, y = admix$y,
                   penalty = "lasso",
                   non_genomic = 1, # mark ancestry variable as non-genomic 
                   # make the penalty factor 0 to keep the corresponding covariate unpenalized
                   penalty_factor = c(0, rep(1, ncol(admix$X))))

summary(admix_fit2, idx = 95)
plot(admix_fit2)
```

## Cross validation 

To select a $\lambda$ value, we often use cross validation. Below is an example of using `cv_plmm` to select a $\lambda$ that minimizes cross-validation error: 

```{r admix_cv}
admix_cv <- cv_plmm(X = X_plus_ancestry, y = admix$y,
                    penalty = "lasso",
                    non_genomic = 1, # mark ancestry variable as non-genomic
                    penalty_factor = c(0, rep(1, ncol(admix$X))))
admix_cv_s <- summary(admix_cv, lambda = "min")
print(admix_cv_s)
```

We can also plot the cross-validation error (CVE) versus $\lambda$ (on the log scale):

```{r cvplot, fig.align='center', fig.width=8, fig.cap="Plot of CVE"}
plot(admix_cv)
```

## Predicted values 

Below is an example of the `predict()` methods for PLMMs: 

```{r admix_pred}
# make predictions for select lambda value(s)
y_hat <- predict(object = admix_fit,
                       newX = admix$X,
                       type = "blup",
                       X = admix$X,
                       y = admix$y)

```

We can compare these predictions with the predictions we would get from an intercept-only model using mean squared prediction error (MSPE) -- lower is better:

```{r}
# intercept-only (or 'null') model
crossprod(admix$y - mean(admix$y))/length(admix$y)

# our model at its best value of lambda
apply(y_hat, 2, function(c){crossprod(admix$y - c)/length(c)}) -> mse
min(mse)
# ^ across all values of lambda, our model has MSPE lower than the null model
```

We see our model has better predictions than the null
