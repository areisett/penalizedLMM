---
title: "Analyze high-dimensional PLINK data with filebacking"
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval = FALSE,
  comment = "#>") 
options(rmarkdown.html_vignette.check_title = FALSE)
# TODO: get the filepath issues sorted out so that I can set eval = TRUE
```

```{r setup}
library(plmmr)
# MUST have biglasso version >= 1.5.2.1 - uncomment & run line below if needed
# remotes::install_github(repo = "YaohuiZeng/biglasso") 

library(biglasso)
library(bigsnpr)
```

**Preliminary note**: rendering this vignette is proving to be tricky, given that these examples read in external data files. Right now, this renders on my local machine -- I am still working out the kinks of getting this to render for our website. For now, I've left `eval=FALSE` just so you all can at least see the code. Let me know if you have any questions. --Tabitha

In many applications of high dimensional data analysis, the dataset is too large to read into R -- the session will crash for lack of memory. This is almost always an issue with analyzing genetic data from [PLINK](https://www.cog-genomics.org/plink/) files. To analyze such large datasets, `plmmr` is equipped to analyze data using *filebacking* - a strategy that lets R 'point' to a file on disk, rather than reading the file into the R session. Many other packages use this technique - [bigstatsr](https://privefl.github.io/bigstatsr/) and [biglasso](https://github.com/pbreheny/biglasso) are two examples of packages that use filebacking. The novelties of `plmmr` are:

(1) **Integration**: `plmmr` combines the functionality of several packages in order to do quality control, model fitting/analysis, and data visualization all in one package. `plmmr` will take you from PLINK files all the way to a list of SNPs for downstream analysis.

(2) **Accessibility**: `plmmr` can be run from an `R` session on a typical desktop/laptop machine. The user does not need access to a supercomputer or experience with the command line in order to fit models `plmmr`. If you don't know what the 'command line' means, don't worry - `plmmr` was designed with you in mind :)

(3) **Handling correlation**: `plmmr` uses a transformation that addresses correlation among samples and uses this correlation to improve predictions (via the best linear unbiased predictor, or BLUP). This means that in `plmm()`, there's no need to filter data down to a 'maximum subset of unrelated individuals.'

The tutorial that follows will walk you through each step of the process. We will use the `penncath_lite` data that ships with our `plmmr` package -- if you've installed this package, you have this dataset as a set of PLINK files. These PLINK files represent about 1400 participants and 4,000+ SNPs. This dataset is small enough that we could read it into memory (4,000 is a small number of SNPs to study), but I will analyze it using filebacked methods here for the sake of example. The steps shown here would be the same for GWAS-sized datasets (100,000 - 800,000 SNPs). More information about the `penncath_lite` data is given in the `PLINK files` article. **Note**: if you haven't done so already, go ahead and [unzip the PLINK files that came with `plmmr`]{style="color:purple"}

If you are on MacOS or Linux, you can run this command to unzip: 
```{r, eval=FALSE}
temp_dir <- tempdir() # using a temp dir -- change to fit your preference
unzip_example_data(outdir = temp_dir)
```

# Analyzing filebacked data from start to finish

## Step 1: preprocess the data

The most important step is where you begin -- for GWAS data, we have to tell `plmmr` how to combine information across all three PLINK files (the `.bed`, `.bim`, and `.fam` files).

Here, we will create the files we want in a temporary directory just for the sake of example. Users can specify the folder of their choice for `rds_dir`, as shown below:

```{r}
temp_dir <- paste0(tempdir()) # using a temporary directory (if you didn't already create one above)

plink_data <- process_plink(data_dir = find_example_data(parent = TRUE), 
                            # find_example_data() will read in data that 'shipped' with the package, 
                            # once it has been unzipped (assuming you unzipped in the same folder)
              rds_dir = temp_dir,
              prefix = "penncath_lite",
              overwrite = TRUE,
              impute_method = "mode")
```

You'll see a lot of messages printed to the console here ... the result of all this is the creation of 3 files: `std_penncath_lite.rds` and `std_penncath_lite.bk` contain the data, and `process_plink.log` is a text file documenting the steps that were just done. These will show up in the folder where the PLINK data is; the file path to the .rds object is returned here to `plink_data`

We can examine what's in `std_penncath_lite.rds` using the `snp_attach()` function from the `bigsnpr` package:

```{r}
pen <- readRDS(plink_data)
str(pen) # note: genotype data is *not* in memory
# notice: no more missing values in X
any(is.na(pen$genotypes[,]))
```

To prepare for data analysis, we need to use the data to create the pieces we need for our model: a design matrix $\mathbf{X}$, an outcome vector $\mathbf{y}$, and a the vector with the penalty factor indicators (1 = feature will be penalized, 0 = feature will not be penalized). 

```{r}
pen_design <- create_design(dat = plink_data,
                            prefix = "penncath_lite",
                            is_bigsnp = TRUE,
                            id_var = "FID",
                            add_predictor_ext = extdata)
                            

# we can check to see that our data have been standardized 
std_X <- attach.big.matrix(pen$std_X)
colMeans(std_X[,]) |> summary() # columns have mean zero...
apply(std_X[,], 2, var) |> summary() # ... & variance 1
```



### What if my data aren't in PLINK format?

The methodology in `plmmr` was motivated by applications in GWAS, but it certainly isn't limited to that context. Suppose you have a high dimensional data set, such as the `colon2` data -- this is like the `colon` data that ships with the `biglasso` package, only here I've inserted some NA values just for didactic purposes.

```{r}
colon_data <- process_delim(file = "colon2.txt",
          data_dir = find_example_data(parent = TRUE),
          rds_dir = temp_dir,
          ind.col = 2:2002) # don't use the 1st column; it has IDs in it

std_colon2 <- readRDS(file = colon_data)
str(std_colon2) # notice that the columns with NA values were dropped 
```

## Step 2: fit a model

Note: for data coming from `process_plink()`, the `y` argument in `plmm()` defaults to using the 6th column from the '.fam' file as the phenotype/outcome (this behavior is the same as what PLINK does).

```{r}
fb_fit <- plmm(X = plink_data,
               returnX = FALSE,
               # this datset is small enough to fit in memory
               # by setting returnX = FALSE, I force plmm() to run on the filebacked data
               save_rds = file.path(temp_dir, "fb_fit"),
               # save results to my temp directory, and name files 'fb_fit'
               trace = TRUE)
```


We can confirm that our filebacked methods and in-memory methods give the same results:
```{r}
fit <- plmm(X = plink_data, # will run in-memory by default, since data will fit
            trace = TRUE)

b1 <- fb_fit$beta_vals |> as.matrix()
b2 <- fit$beta_vals
tinytest::expect_equivalent(b1, b2, 0.01) 
```

The format is similar for data that came from `process_delim` -- however, in the case of our `colon2` data, we need to supply our own kinship matrix. The data are not genomic, so estimating a genomic relatedness matrix doesn't make sense. For our purposes, we will make up a 'dummy' K matrix.

```{r}
# pretend genomic data from 500 SNPs
genomic_dat <- matrix(sample(0:2, 62*500, replace = TRUE), nrow = 62, ncol = 500)
K <- relatedness_mat(genomic_dat)
pretend_outcome <- rnorm(62) # notice: this is a completely made-up outcome
# depending on the seed used for this rnorm() call, results may look aberrant/'weird'
colon2_fit <- plmm(X = file.path(temp_dir, "std_colon2"),
                   y = pretend_outcome,
                   K = K,
                   returnX = FALSE,
                   trace = TRUE)

plot(colon2_fit)
```

## Step 3: Plot/summarize results

To summarize a single model (no CV), we can look at a plot of the coefficient paths:

```{r}
plot(fb_fit)
```

We can also examine the number of selected variables at a particular index of $\lambda$:

```{r}
summary(fb_fit, idx = 50)
```


## Step 4: Cross-validation (tuning parameter selection)

In most applications, we will want to fit a model using cross validation in order to choose an appropriate value of $\lambda$, the tuning parameter for our penalized model.

```{r}
cv_fb_fit <- cv_plmm(X = plink_data,
                     type = 'blup',
                     returnX = FALSE,
                     nfolds = 3, # for sake of testing, I made this small. 
                     # In practice, 3 folds is usually not enough for robust 
                     # cross validation - hence, the default is nfolds = 5
                     returnBiasDetails = TRUE,
                     trace = TRUE,
                     save_rds = file.path(plink_data,
                                          "cv"), # save_results to save folder as data 
                     save_fold_res = TRUE, # saves loss and predictions in each fold
                     compact_save = TRUE, # saves results in separate files
                     seed = 123)

```

Fitting an equivalent model using the `penncath_lite` data that uses RAM could look like this: 

```{r, eval=FALSE}
cv_fit <- cv_plmm(X = plink_data,
                  type = 'blup',
                  nfolds = 3,
                  returnBiasDetails = TRUE,
                  trace = TRUE,
                  seed = 123)

print(summary(cv_fit))
plot(cv_fit)
tinytest::expect_equivalent(cv_fb_fit$cve, cv_fit$cve, tolerance = 0.01)
```

To summarize and plot a CV fit, we can look at a plot of cross validation error:

```{r}
plot(cv_fb_fit)
```

To summarize and visualize the model at the chosen $\lambda$ parameter value, we can do this:

```{r}
summary(cv_fb_fit)
```

## Comparing candidate models

The default penalty in `plmmr` is the lasso. Another option would be the minimax-concave penalty (MCP)[^2]. Suppose we want to compare our lasso-penalized model results with a MCP-penalized model. We can fit a lasso model as shown:

[^1]: Zhang, Cun-Hui. "Nearly unbiased variable selection under minimax concave penalty." (2010): 894-942.

```{r}
fb_mcp <- plmm(X = plink_data,
                 penalty = "MCP",
                 returnX = FALSE,
                 trace = TRUE)

plot(fb_mcp)
summary(fb_mcp, idx = 50)
```

## To add predictors that are not genomic

In many biological applications, we want to include some features/covariates/predictors in addition to the genomic information, like clinical or demographic information. Let's suppose that in the `penncath` data analysis, we want to include 'sex' and 'age' as unpenalized covariates. We can do this by supplying an additional argument to `process_plink()`:

```{r}
# create a new temporary directory, to avoid over-writing saved results
temp_dir2 <- paste0(tempdir(), sample(LETTERS, 1))
unzip_example_data(outdir = temp_dir2) # change this line if you're working on Windows

pen_clinic <- read.csv(paste0(find_example_data(parent = TRUE), "/penncath_clinical.csv"))
extdata <- pen_clinic[,3:4]
rownames(extdata) <- pen_clinic$FamID # This is important! 

# create a new temporary directory
new_plink_data <- process_plink(data_dir = temp_dir2,
              # again, adjust this to wherever you've got the unzipped PLINK data
              rds_dir = temp_dir2, # using a temporary directory
              prefix = "penncath_lite",
              id_var = "FID", # this is KEY!
              outfile = file.path(temp_dir2,"process_penncath_addvar"),
              impute_method = "mode",
              add_predictor_ext = extdata)

# check this out: 
pen2 <- readRDS(new_plink_data)
pen2$std_X_colnames |> head() # std_X includes our non-genomic covariates 
pen2$std_X <- bigmemory::attach.big.matrix(pen2$std_X)
```

We usually want these kinds of variables to always be in the model (i.e., they are not penalized). To make sure 'sex' and 'age' are always included in the chosen model, let's set `penalty_factor` to have 0 values corresponding to these predictors.

```{r}
fit_plus_newvars <- plmm(X = new_plink_data,
                         penalty_factor = c(0, 0, rep(1, ncol(pen2$std_X) - 2)),
                         K = fb_fit$K, 
                         returnX = FALSE,
                         trace = TRUE)
```

We can check out how these additional covariates impact model fit:

```{r}
plot(fit_plus_newvars)

summary(fb_fit, idx = 1) 
summary(fit_plus_newvars, idx = 1) # at highest penalty value, sex and age are still in the model

# look at the estimated coefficients 
fb_fit$beta_vals[1:10, 1:5]
fit_plus_newvars$beta_vals[1:10, 1:5]
```
