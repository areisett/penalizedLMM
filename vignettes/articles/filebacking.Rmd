---
title: "Analyze high-dimensional PLINK data with filebacking"
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  eval = FALSE,
  comment = "#>") 
options(rmarkdown.html_vignette.check_title = FALSE)
# TODO: get the filepath issues sorted out so that I can set eval = TRUE
```

```{r setup}
library(plmmr)
# MUST have biglasso version >= 1.5.2.1 - uncomment & run line below if needed
# remotes::install_github(repo = "YaohuiZeng/biglasso") 

library(biglasso)
library(bigsnpr)
```

**Preliminary note**: rendering this vignette is proving to be tricky, given that these examples read in external data files. Right now, this renders on my local machine -- I am still working out the kinks of getting this to render for our website. For now, I've left `eval=FALSE` just so you all can at least see the code. Let me know if you have any questions. --Tabitha 

In many applications of high dimensional data analysis, the dataset is too large to read into R -- the session will crash for lack of memory. This is almost always an issue with analyzing genetic data from [PLINK](https://www.cog-genomics.org/plink/) files. To analyze such large datasets, `plmmr` is equipped to analyze data using *filebacking* - a strategy that lets R 'point' to a file on disk, rather than reading the file into the R session. Many other packages use this technique - [bigstatsr](https://privefl.github.io/bigstatsr/) and [biglasso](https://github.com/pbreheny/biglasso) are two examples of packages that use filebacking. The novelties of `plmmr` are: 

  (1) **Integration**: `plmmr` combines the functionality of several packages in order to do quality control, model fitting/analysis, and data visualization all in one package. `plmmr` will take you from PLINK files all the way to a list of SNPs for downstream analysis. 
  
  (2) **Accessibility**: `plmmr` can be run from an `R` session on a typical desktop/laptop machine. The user does not need access to a supercomputer or experience with the command line in order to fit models `plmmr`. If you don't know what the 'command line' means, don't worry - `plmmr` was designed with you in mind :) 
  
  (3) **Handling correlation**: `plmmr` uses a transformation that addresses correlation among samples and uses this correlation to improve predictions (via the best linear unbiased predictor, or BLUP). This means that in `plmm()`, there's no need to filter data down to a 'maximum subset of unrelated individuals.' 
  
  The tutorial that follows will walk you through each step of the process. We will use the `penncath_lite` data that ships with our `plmmr` package -- if you've installed this package, you have this dataset as a set of PLINK files. These PLINK files represent about 1400 participants and 4,000+ SNPs. This dataset is small enough that we could read it into memory (4,000 is a small number of SNPs to study), but I will analyze it using filebacked methods here for the sake of example. The steps shown here would be the same for GWAS-sized datasets (100,000 - 800,000 SNPs). More information about the `penncath_lite` data is given in the `PLINK files` article. 
  
  
# Analyzing filebacked data from start to finish

## Step 1: preprocess the data

The most important step is where you begin -- for GWAS data, we have to tell `plmmr` how to combine information across all three PLINK files (the `.bed`, `.bim`, and `.fam` files). Here, we will create the files we want in a temporary directory just for the sake of example. Users can specify the folder of their choice for `rds_dir`, as shown below: 

```{r}
temp_dir <- paste0(tempdir(),"/") # using a temporary directory
process_plink(data_dir = get_example_data(parent = TRUE), # reads data from inst/extdata
              rds_dir = temp_dir,
              prefix = "penncath_lite",
              gz = TRUE,
              outfile = "process_penncath",
              overwrite = TRUE,
              impute_method = "mode")
```

You'll see a lot of messages printed to the console here ... the result of all this is the creation of 2 files (these will show up in the folder where the PLINK data is): `std_penncath_lite.rds` and `std_penncath_lite.bk.` 

We can examine what's in `std_penncath_lite.rds` using the `snp_attach()` function from the `bigsnpr` package:

```{r}
pen <- readRDS(file.path(temp_dir, "std_penncath_lite.rds"))
str(pen) # note: genotypes and std_X are *not* in memory
# 
# we can check to see that our data have been standardized 
std_X <- pen$std_X[,]
colMeans(std_X) |> summary() # columns have mean zero...
apply(std_X, 2, var) |> summary() # ... & variance 1
```

### What if my data aren't in PLINK format? 

The methodology in `plmmr` was motivated by applications in GWAS, but it certainly isn't limited to that context. Suppose you have a high dimemsional data set, such as the `colon2` data -- this is like the `colon` data that ships with the `biglasso` package, only here I've inserted some NA values just for didactic purposes.

```{r}
process_delim(file = "colon2.txt",
          data_dir = get_example_data(parent = TRUE),
          rds_dir = temp_dir,
          ind.col = 2:2002) # don't use the 1st column; it has IDs in it

colon2 <- readRDS(file = file.path(temp_dir, "std_colon2.rds"))
str(colon2) # notice that the columns with NA values were dropped 
```


## Step 2: fit a model 

Note: for data coming from `process_plink()`, the `y` argument in `plmm()` defaults to using the 6th column from the '.fam' file as the phenotype/outcome (this is the same as what PLINK does).

```{r}
my_fb_data <- paste0(temp_dir, "std_penncath_lite")
fb_fit <- plmm(X = my_fb_data,
               returnX = FALSE, 
               # this datset is small enough to fit in memory
               # by setting returnX = FALSE, I force plmm() to run on the filebacked data
               trace = TRUE)
```

The format is similar for data that came from `process_delim` -- however, in the case of our `colon2` data, we need to supply our own kinship matrix. The data are not genomic, so estimating a genomic relatedness matrix doesn't make sense. For our purposes, we will make up a 'dummy' K matrix. 

```{r}
# pretend genomic data from 500 SNPs
genomic_dat <- matrix(sample(0:2, 62*500, replace = TRUE), nrow = 62, ncol = 500)
K <- relatedness_mat(genomic_dat)

colon2_fit <- plmm(X = file.path(temp_dir, "std_colon2"),
                   y = rnorm(62),
                   K = K,
                   returnX = FALSE,
                   trace = TRUE)
```



In most applications, we will want to fit a model using cross validation 

```{r}
cv_fb_fit <- cv.plmm(X = my_fb_data,
                     type = 'blup',
                     returnX = FALSE,
                     nfolds = 3, # for sake of testing, I made this small. 
                     # In practice, 3 folds is usually not enough for robust 
                     # cross validation - hence, the default is nfolds = 10
                     returnBiasDetails = TRUE,
                     trace = TRUE)
```


## Step 3: Plot/summarize results 

To summarize a single model (no CV), we can look at a plot of the coefficient paths: 

```{r}
plot(fb_fit)
```

We can also examine the number of selected variables at a particular index of $\lambda$: 
```{r}
summary(fb_fit, idx = 50)
```

To summarize and plot a CV fit, we can look at a plot of cross validation error: 

```{r}
plot(cv_fb_fit)
```

To summarize and visualize the model at the chosen $\lambda$ parameter value, we can do this:

```{r}
summary(cv_fb_fit)
```

## Comparing candidate models 

The default penalty in `plmmr` is the minimax-concave penalty (MCP)^[Zhang, Cun-Hui. "Nearly unbiased variable selection under minimax concave penalty." (2010): 894-942.]. Suppose we want to compare our MCP-penalized model results with a lasso-penalized model. We can fit a lasso model as shown:

```{r}
fb_lasso <- plmm(X = my_fb_data,
                 penalty = "lasso",
                 returnX = FALSE,
                 trace = TRUE)

plot(fb_lasso)
summary(fb_lasso, idx = 50)


# with CV 
cv_fb_lasso <- cv.plmm(X = my_fb_data,
                       penalty = "lasso",
                     type = 'blup',
                     nfolds = 3, 
                     returnX = FALSE,
                     trace = TRUE)

plot(cv_fb_lasso)

summary(cv_fb_lasso)
```

## To add predictors that are not genomic

In many biological applications, we want to include some features/covariates/predictors in addition to the genomic information, like clinical or demographic information. Let's suppose that in the `penncath` data analysis, we want to include 'sex' and 'age' as unpenalized covariates. We can do this by supplying an additional argument to `process_plink()`: 

```{r}
pen_clinic <- read.csv(paste0(get_example_data(parent = TRUE), "/penncath_clinical.csv"))
extdata <- pen_clinic[,3:4]
rownames(extdata) <- pen_clinic$FamID # This is important! 

# create a new temporary directory
temp_dir2 <- paste0(tempdir(), sample(LETTERS, 1))

process_plink(data_dir = get_example_data(parent = TRUE),
              rds_dir = temp_dir2, # using a temporary directory
              prefix = "penncath_lite",
              id_var = "FID", # this is KEY!
              outfile = "process_penncath",
              impute_method = "mode",
              add_predictor_ext = extdata)

# check this out: 
pen2 <- readRDS(paste0(temp_dir2, "/std_penncath_lite.rds"))
pen2$std_X_colnames |> head() # std_X includes our non-genomic covariates 
```


We usually want these kinds of variables to always be in the model (i.e., they are not penalized). To make sure 'sex' and 'age' are always included in the chosen model, let's set `penalty.factor` to have 0 values corresponding to these predictors. 

```{r}
dat_plus_newvars <- paste0(temp_dir2, "/std_penncath_lite")
fit_plus_newvars <- plmm(X = dat_plus_newvars,
               penalty.factor = c(0, 0, rep(1, ncol(pen2$std_X) - 2)),
                K = list(U = fb_fit$U[,], s = fb_fit$s), 
               returnX = FALSE,
               trace = TRUE)
```

We can check out how these additional covariates impact model fit: 

```{r}
plot(fit_plus_newvars)

summary(fb_fit, idx = 1) 
summary(fit_plus_newvars, idx = 1) # at highest penalty value, sex and age are still in the model

# look at the estimated coefficients 
fb_fit$beta_vals[1:10, 1:5]
fit_plus_newvars$beta_vals[1:10, 1:5]
```

